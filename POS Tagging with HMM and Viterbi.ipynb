{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS Tagging using HMM and Viterbi\n",
    "A hidden Markov model (HMM) allows us to talk about both observed events (like words that we see in the input) and hidden events (like part-of-speech tags) in our probabilistic model. An HMM is speciﬁed by the following components:\n",
    "\n",
    "$Q = q_1 q_2 ...q_N$\n",
    "\n",
    "a set of N states\n",
    "\n",
    "$A = a_{11} ...a_{ij} ...a_{NN}$\n",
    "\n",
    "a transition probability matrix A, each a ij representing the probability of moving from state i to state j, s.t. $\\sum^{N}_{j=1}a_{ij} = 1 ∀i$\n",
    "\n",
    "$O = o_1 o_2 ...o_T$\n",
    "\n",
    "a sequence of T observations, each one drawn from a vocabulary $V = v_1 ,v_2 ,...,v_V$\n",
    "\n",
    "$B = b_i (o_t )$\n",
    "\n",
    "a sequence of observation likelihoods, also called emission probabilities, each expressing the probability of an observation $o_t$ being generated from a state $q_i$ \n",
    "\n",
    "$π = π_1 ,π_2 ,...,π_N$\n",
    "\n",
    "an initial probability distribution over states. $π_i$ is the probability that the Markov chain will start in state i. Some states j may have $π_j$ = 0, meaning that they cannot be initial states. Also, $\\sum_{i=1}^n π_i = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_file = './data/wsj_sec0_pos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def process_line(s):\n",
    "    words = ['bos']\n",
    "    tags = ['BOS']\n",
    "    for item in s.split(' '):\n",
    "        w, t = '/'.join(item.split('/')[:-1]), item.split('/')[-1]\n",
    "        words.append(w)\n",
    "        tags.append(t)\n",
    "    return words+['eos'], tags+['EOS']\n",
    "\n",
    "data = []\n",
    "\n",
    "with open(pos_file, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        data.append(process_line(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['bos', 'Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.', 'eos'], ['BOS', 'NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'MD', 'VB', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'CD', '.', 'EOS'])\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "transition_prob = defaultdict(dict)\n",
    "emission_prob = defaultdict(dict)\n",
    "state_set = set()\n",
    "transition_cnt = Counter()\n",
    "tag_cnt = Counter()\n",
    "emission_cnt = Counter()\n",
    "\n",
    "for s in data:\n",
    "    words, tags = s\n",
    "    tag_cnt.update(tags)\n",
    "    for bi_t in zip(*[tags[i:] for i in range(2)]):\n",
    "        transition_cnt.update((bi_t,))\n",
    "    for t_w in zip(tags, words):\n",
    "        emission_cnt.update((t_w,))\n",
    "\n",
    "for item in sorted(transition_cnt.items()):\n",
    "    tran, cnt = item\n",
    "    prob = cnt / tag_cnt[tran[0]]\n",
    "    transition_prob[tran[0]][tran[1]] = prob\n",
    "    state_set.update(list(tran))\n",
    "\n",
    "for item in sorted(emission_cnt.items()):\n",
    "    emi, cnt = item\n",
    "    prob = cnt / tag_cnt[emi[0]]\n",
    "    emission_prob[emi[0]][emi[1]] = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('WDT',\n",
       " {'CD': 0.005025125628140704,\n",
       "  'DT': 0.03015075376884422,\n",
       "  'EX': 0.005025125628140704,\n",
       "  'IN': 0.005025125628140704,\n",
       "  'JJS': 0.005025125628140704,\n",
       "  'MD': 0.11055276381909548,\n",
       "  'NNP': 0.010050251256281407,\n",
       "  'NNS': 0.010050251256281407,\n",
       "  'PRP': 0.04020100502512563,\n",
       "  'RB': 0.06532663316582915,\n",
       "  'RBR': 0.005025125628140704,\n",
       "  'TO': 0.005025125628140704,\n",
       "  'VBD': 0.18090452261306533,\n",
       "  'VBN': 0.005025125628140704,\n",
       "  'VBP': 0.20603015075376885,\n",
       "  'VBZ': 0.3065326633165829,\n",
       "  '``': 0.005025125628140704})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.choice(list(transition_prob.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('PRP',\n",
       " {'He': 0.03982777179763186,\n",
       "  'I': 0.059203444564047365,\n",
       "  'It': 0.059203444564047365,\n",
       "  'She': 0.0193756727664155,\n",
       "  'They': 0.03552206673842842,\n",
       "  'We': 0.03336921420882669,\n",
       "  'You': 0.008611410118406888,\n",
       "  'he': 0.12701829924650163,\n",
       "  'her': 0.017222820236813777,\n",
       "  'herself': 0.001076426264800861,\n",
       "  'him': 0.00968783638320775,\n",
       "  'himself': 0.0032292787944025836,\n",
       "  'it': 0.26480086114101187,\n",
       "  'itself': 0.0032292787944025836,\n",
       "  'me': 0.004305705059203444,\n",
       "  'one': 0.002152852529601722,\n",
       "  'she': 0.07104413347685684,\n",
       "  'them': 0.038751345532831,\n",
       "  'themselves': 0.008611410118406888,\n",
       "  'they': 0.12594187298170076,\n",
       "  'us': 0.012917115177610334,\n",
       "  'we': 0.02583423035522067,\n",
       "  'you': 0.02906350914962325})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(list(emission_prob.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viterbi Decoding\n",
    "Viterbi is an instance of dynamic programming. Given that we had already computed the probabilbeing in every state at time $t−1$, we compute the Viterbi probability by taking the most probable of the extensions of the paths that lead to the current cell.\n",
    "\n",
    "$v_t(j) = max^N_{i=1} v_{t-1}(i) a_{ij} b_j (o_t )$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def viterbi(state, observation, hmm):\n",
    "    \"\"\"\n",
    "    state: list of all states\n",
    "    observation: list of observation\n",
    "    hmm: HMM model created\n",
    "    \"\"\"\n",
    "    N, T = len(state), len(observation) # N: length of state graph, T: length of observation\n",
    "    viterbi_matrix = np.zeros([N, T]) # create matrix for path probability\n",
    "    backpointer = np.zeros([N, T])\n",
    "    # initialization\n",
    "    for s in range(N):\n",
    "        try:\n",
    "            a = hmm['transition']['BOS'][state[s]]\n",
    "            viterbi_matrix[s][0] = hmm['emission'][state[s]][observation[0]] * a\n",
    "        except:\n",
    "            pass\n",
    "        backpointer[s][0] = 0\n",
    "    # recursion\n",
    "    for t in range(1, T):\n",
    "        for s in range(N):\n",
    "            a = np.array([hmm['transition'][s_].get(state[s], 0) for s_ in state])\n",
    "            b = hmm['emission'][state[s]].get(observation[t], 0)\n",
    "            viterbi_matrix[s][t] = np.max(viterbi_matrix[:,t-1] * a * b)\n",
    "            backpointer[s][t] = np.argmax(viterbi_matrix[:,t-1] * a * b)\n",
    "    # find the best path\n",
    "    best_path_prob = np.max(viterbi_matrix[:, -1])\n",
    "    best_path_pointer = int(np.argmax(viterbi_matrix[:, -1]))\n",
    "    best_path = [best_path_pointer]\n",
    "    for t in range(1, T)[::-1]:\n",
    "        best = int(backpointer[best_path_pointer][t])\n",
    "        best_path = [best] + best_path\n",
    "        best_path_pointer = best\n",
    "    best_path = [state[i] for i in best_path]\n",
    "    return best_path, best_path_prob\n",
    "\n",
    "def get_pos(s, state, hmm):\n",
    "    \"\"\"\n",
    "    s: input sentence (observation)\n",
    "    state: list of all states\n",
    "    hmm: HMM model created\n",
    "    \"\"\"\n",
    "    s_list = s.strip().split()\n",
    "    symbol_set = set([x for y in [list(item.keys()) for item in hmm['emission'].values()] for x in y])\n",
    "    s_list = [c if c in symbol_set else '<unk>' for c in s_list]\n",
    "    best_path, best_path_prob = viterbi(state, s_list, hmm)\n",
    "    return best_path, best_path_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = dict()\n",
    "hmm['transition'] = transition_prob\n",
    "hmm['emission'] = emission_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['NNP',\n",
       "  'NNP',\n",
       "  'VBZ',\n",
       "  'NN',\n",
       "  'IN',\n",
       "  'NNP',\n",
       "  'NNP',\n",
       "  ',',\n",
       "  'DT',\n",
       "  'NNP',\n",
       "  'NN',\n",
       "  'NN',\n",
       "  '.'],\n",
       " 2.3389568232423102e-37)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = \"Mr. Vinken is chairman of Elsevier N.V. , the Dutch publishing group .\"\n",
    "get_pos(test_text, list(state_set), hmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
